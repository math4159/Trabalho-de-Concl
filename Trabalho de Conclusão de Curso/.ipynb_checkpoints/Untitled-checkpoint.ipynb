{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c28c99-95d3-4435-a52f-727b5c569e9e",
   "metadata": {},
   "source": [
    "# *1.Trabalho de Conclus√£o de Curso*.\n",
    "\n",
    "    Esse Projeto tem como finalidade aplicar modelos bayesianos √† uma base de dados Fornecida pela ANEEL, referente a interrup√ß√µes el√©tricas. Busca-se analidar a rela√ß√£o prob√°bilistica entre as variaveis de interrup√ß√£o, horario, regi√£o, concession√°ria, tipo da interrup√ß√£o, interrup√ß√£o em certo n√©vel de tens√£o e o fator de causalidade da interrup√ß√£o. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94ba28-8c0b-49a4-b920-09feea1b32ce",
   "metadata": {},
   "source": [
    "### 1.2 Importa√ß√£o de Bibliotecas \n",
    "\n",
    "* Panadas: A√°lises de Data Frames \n",
    "* Pgmpy: Aplica√ß√£o de Redes Bayesianas \n",
    "* Numpy: Opera√ß√µes Matem√°ticas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037057f5-b6f4-45d1-bf83-58c2271b6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BayesianEstimator, HillClimbSearch, BicScore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a12a7-5f8c-4ffc-87ee-0a7c7fb39949",
   "metadata": {},
   "source": [
    "### 1.3 Fun√ß√µes Realizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcac511-84b2-4736-97af-d217e115fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_data_hora(data, colunas):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para separar as colunas de data e hora em um DataFrame.\n",
    "\n",
    "    Par√¢metros:\n",
    "    data (pd.DataFrame): DataFrame contendo as colunas a serem separadas.\n",
    "    colunas (list): Lista com os nomes das colunas a serem separadas.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame com as colunas de data e hora separadas.\n",
    "    \"\"\"\n",
    "    for coluna in colunas:\n",
    "        if coluna in data.columns:\n",
    "            data[[coluna, f'Hor{coluna[3:]}']] = data[coluna].str.split(' ', expand=True)\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ef48cd-25ad-4982-a031-dd6372a34674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_interrupcoes(data):\n",
    "    \"\"\"\n",
    "    Processa as colunas de data e hora em um DataFrame grande, combinando-as e calculando a dura√ß√£o da interrup√ß√£o.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    data (pd.DataFrame): DataFrame contendo as colunas de data e hora.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame atualizado com colunas formatadas e a dura√ß√£o da interrup√ß√£o.\n",
    "    \"\"\"\n",
    "\n",
    "    # Converter colunas de data para string (reduz mem√≥ria se forem objetos)\n",
    "    data['DatInicioInterrupcao'] = data['DatInicioInterrupcao'].astype('string')\n",
    "    data['DatFimInterrupcao'] = data['DatFimInterrupcao'].astype('string')\n",
    "\n",
    "    # Concatenar data e hora para criar colunas completas de datetime\n",
    "    data['InicioInterrupcao'] = pd.to_datetime(\n",
    "        data['DatInicioInterrupcao'] + ' ' + data['HorInicioInterrupcao'], \n",
    "        errors='coerce',  # Evita erros se houver valores inv√°lidos\n",
    "        format='%Y-%m-%d %H:%M:%S'  # Define o formato esperado para otimiza√ß√£o\n",
    "    )\n",
    "\n",
    "    data['FimInterrupcao'] = pd.to_datetime(\n",
    "        data['DatFimInterrupcao'] + ' ' + data['HorFimInterrupcao'], \n",
    "        errors='coerce',\n",
    "        format='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "\n",
    "    # Converter datas para datetime com infer√™ncia de formato\n",
    "    data['DatInicioInterrupcao'] = pd.to_datetime(data['DatInicioInterrupcao'], errors='coerce')\n",
    "    data['DatFimInterrupcao'] = pd.to_datetime(data['DatFimInterrupcao'], errors='coerce')\n",
    "\n",
    "    # Calcular a dura√ß√£o da interrup√ß√£o (em horas)\n",
    "    data['DuracaoInterrupcao'] = (data['FimInterrupcao'] - data['InicioInterrupcao']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Liberar mem√≥ria removendo colunas desnecess√°rias\n",
    "    data.drop(columns=['HorInicioInterrupcao', 'HorFimInterrupcao'], inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c583393-a05f-4f8e-a081-a4b321a14da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_numTensao(numTensao):\n",
    "    if numTensao <= 1000.0:\n",
    "        return 'Baixa Tens√£o'\n",
    "    elif 1000.0 < numTensao <= 36000.0:\n",
    "        return 'M√©dia Tens√£o'\n",
    "    elif numTensao > 36000.0:\n",
    "        return 'Alta Tens√£o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6c04cb-9fee-4314-a520-7c985c042bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fun√ß√£o para classificar o turno\n",
    "def identificar_turno(horario):\n",
    "    # Extrair a hora do Timestamp\n",
    "    hora = horario.hour\n",
    "    if 6 <= hora < 12:\n",
    "        return 'Manh√£'\n",
    "    elif 12 <= hora < 18:\n",
    "        return 'Tarde'\n",
    "    else:\n",
    "        return 'Noite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a72f128b-cec9-45c7-9e02-847115433531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_duracao(duracao):\n",
    "    \"\"\"\n",
    "    Categoriza a dura√ß√£o da interrup√ß√£o em faixas predefinidas.\n",
    "\n",
    "    Par√¢metros:\n",
    "    - duracao (float): Dura√ß√£o da interrup√ß√£o em horas.\n",
    "\n",
    "    Retorna:\n",
    "    - str: Categoria correspondente √† dura√ß√£o.\n",
    "    \"\"\"\n",
    "    if duracao < 0.05:\n",
    "        return 'Ru√≠do'\n",
    "    elif 0.05 <= duracao < 0.25:\n",
    "        return 'Interrup√ß√£o muito pequena'\n",
    "    elif 0.25 <= duracao < 0.5:\n",
    "        return 'Interrup√ß√£o pequena'\n",
    "    elif 0.5 <= duracao < 3:\n",
    "        return 'M√©dia'\n",
    "    elif 3 <= duracao < 6:\n",
    "        return 'Grande em √°rea urbana'\n",
    "    elif 6 <= duracao < 10:\n",
    "        return 'Grande em √°rea rural'\n",
    "    elif 10 <= duracao < 24:\n",
    "        return 'Preocupante'\n",
    "    else:  # duracao >= 24\n",
    "        return 'Anomalia'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957319f5-de40-4355-b331-32b8ec2585c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_networkx(bayesian_model):\n",
    "    \"\"\"\n",
    "    Converte um BayesianModel para um DiGraph do networkx.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(bayesian_model.nodes())\n",
    "    G.add_edges_from(bayesian_model.edges())\n",
    "    return G\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def plot_graph_and_save(model, save_dir=\"output\", filename=\"bayesian_network.png\"):\n",
    "    \"\"\"\n",
    "    Plota a estrutura da Rede Bayesiana e salva a imagem em um caminho definido.\n",
    "\n",
    "    Par√¢metros:\n",
    "    - model (nx.DiGraph): Grafo direcionado representando o modelo Bayesiano.\n",
    "    - save_dir (str): Diret√≥rio onde a imagem ser√° salva.\n",
    "    - filename (str): Nome do arquivo a ser salvo.\n",
    "\n",
    "    Retorna:\n",
    "    - Caminho do arquivo salvo.\n",
    "    \"\"\"\n",
    "\n",
    "    # Criar diret√≥rio se n√£o existir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Definir caminho do arquivo\n",
    "    image_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    # Criar a figura e o layout do grafo\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(model)\n",
    "    nx.draw(model, pos, with_labels=True, node_color='lightblue', font_weight='bold', node_size=3000, edge_color=\"gray\")\n",
    "    plt.title(\"Estrutura da Rede Bayesiana\")\n",
    "\n",
    "    # Salvar imagem antes de exibir\n",
    "    plt.savefig(image_path, format=\"png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    return image_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80df51-4784-4fe7-b2ff-4231699b8f0d",
   "metadata": {},
   "source": [
    "## Fun√ß√£o para inferencias e Estruturas Bayesianas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c7e51f-73d3-4488-adfa-f86d536ff55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "import pandas as pd\n",
    "\n",
    "def inferencia_simples(modelo, variavel):\n",
    "    \"\"\"\n",
    "    Realiza infer√™ncia para uma vari√°vel na Rede Bayesiana sem considerar evid√™ncias.\n",
    "\n",
    "    Par√¢metros:\n",
    "    - modelo (BayesianModel): Modelo Bayesiano treinado.\n",
    "    - variavel (str): Vari√°vel de interesse para infer√™ncia.\n",
    "\n",
    "    Retorno:\n",
    "    - DataFrame contendo as probabilidades inferidas para a vari√°vel.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Criar o objeto de infer√™ncia\n",
    "        inferencia = VariableElimination(modelo)\n",
    "\n",
    "        # Realizar a infer√™ncia para a vari√°vel sem evid√™ncias\n",
    "        resultado = inferencia.query(variables=[variavel])\n",
    "\n",
    "        # Criar um DataFrame com os estados e suas probabilidades\n",
    "        df_resultados = pd.DataFrame({\n",
    "            'Vari√°vel': variavel,\n",
    "            'Estado': resultado.state_names[variavel],  # Estados poss√≠veis da vari√°vel\n",
    "            'Probabilidade': resultado.values  # Probabilidades associadas a cada estado\n",
    "        })\n",
    "\n",
    "        return df_resultados\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao realizar infer√™ncia para '{variavel}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Exemplo de uso:\n",
    "# resultado = inferencia_simples(best_model, 'A')\n",
    "# print(resultado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ff019e-65c9-494e-bd61-23861672d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "def inferencia_todas_combinacoes(modelo, categorias):\n",
    "    \"\"\"\n",
    "    Realiza infer√™ncia Bayesiana para todas as vari√°veis do modelo, considerando\n",
    "    todas as poss√≠veis combina√ß√µes de evid√™ncias.\n",
    "\n",
    "    Par√¢metros:\n",
    "    - modelo (BayesianModel): Modelo Bayesiano treinado.\n",
    "    - categorias (dict): Dicion√°rio contendo as categorias de cada vari√°vel.\n",
    "\n",
    "    Retorno:\n",
    "    - DataFrame contendo todas as infer√™ncias realizadas.\n",
    "    \"\"\"\n",
    "    # Criar o objeto de infer√™ncia\n",
    "    inferencia = VariableElimination(modelo)\n",
    "    \n",
    "    # Lista para armazenar os resultados\n",
    "    resultados = []\n",
    "\n",
    "    # Percorrer todas as vari√°veis do modelo\n",
    "    for variavel_alvo in modelo.nodes():\n",
    "        # Criar combina√ß√µes de evid√™ncias usando as demais vari√°veis\n",
    "        variaveis_restantes = [var for var in modelo.nodes() if var != variavel_alvo]\n",
    "        \n",
    "        # Gerar todas as combina√ß√µes poss√≠veis de evid√™ncias\n",
    "        for num_evidencias in range(1, len(variaveis_restantes) + 1):  # De 1 at√© todas as evid√™ncias poss√≠veis\n",
    "            for evidencias_comb in itertools.combinations(variaveis_restantes, num_evidencias):\n",
    "                # Gerar todas as combina√ß√µes de valores para as evid√™ncias escolhidas\n",
    "                valores_possiveis = [categorias[var] for var in evidencias_comb]\n",
    "                for valores_evidencias in itertools.product(*valores_possiveis):\n",
    "                    # Criar o dicion√°rio de evid√™ncias\n",
    "                    evidencias = dict(zip(evidencias_comb, valores_evidencias))\n",
    "\n",
    "                    # Mapear evid√™ncias categ√≥ricas para valores num√©ricos\n",
    "                    evidencias_convertidas = {}\n",
    "                    for var, valor in evidencias.items():\n",
    "                        cpd = modelo.get_cpds(var)\n",
    "                        categorias_var = cpd.state_names[var]\n",
    "                        evidencias_convertidas[var] = categorias_var.index(valor)\n",
    "\n",
    "                    # Realizar infer√™ncia\n",
    "                    resultado = inferencia.query(variables=[variavel_alvo], evidence=evidencias_convertidas)\n",
    "\n",
    "                    # Adicionar os resultados ao DataFrame\n",
    "                    for estado, prob in zip(resultado.state_names[variavel_alvo], resultado.values):\n",
    "                        resultados.append({\n",
    "                            'Vari√°vel Alvo': variavel_alvo,\n",
    "                            'Estado': estado,\n",
    "                            'Probabilidade': prob,\n",
    "                            'Evid√™ncias': evidencias\n",
    "                        })\n",
    "\n",
    "    # Criar um DataFrame com os resultados\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    return df_resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ffa12-7836-4dea-bc50-95ba26094b73",
   "metadata": {},
   "source": [
    "### 1.3 Exporta√ß√£o da Base de Dados e Pr√©-processamento\n",
    "    O Pgmpy n√£o aceita objetct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28531555-278b-4044-b6bd-0a4c4c95d27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1848\\2716428666.py:1: DtypeWarning: Columns (0,2,3,4,5,6,8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv('interrupcoes-energia-eletrica-2024 (2).csv', encoding=\"ISO-8859-1\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('interrupcoes-energia-eletrica-2024 (2).csv', encoding=\"ISO-8859-1\", sep=';')\n",
    "df1=df1.dropna()\n",
    "df1=df1[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DatInicioInterrupcao','DatFimInterrupcao']]\n",
    "\n",
    "colunas_para_separar = ['DatInicioInterrupcao', 'DatFimInterrupcao']\n",
    "df1 = separar_data_hora(df1, colunas_para_separar)\n",
    "\n",
    "df1= processar_interrupcoes(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "945dd977-490a-4834-88e1-9741d514b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1848\\2955413010.py:1: DtypeWarning: Columns (3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('interrupcoes-energia-eletrica-2023.csv', encoding=\"ISO-8859-1\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('interrupcoes-energia-eletrica-2023.csv', encoding=\"ISO-8859-1\", sep=';')\n",
    "df2=df2.dropna()\n",
    "df2=df2[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DatInicioInterrupcao','DatFimInterrupcao']]\n",
    "\n",
    "colunas_para_separar = ['DatInicioInterrupcao', 'DatFimInterrupcao']\n",
    "df2 = separar_data_hora(df2, colunas_para_separar)\n",
    "\n",
    "df2= processar_interrupcoes(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "486b1cd4-4c05-4378-bca5-f14942047277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1848\\1339177106.py:1: DtypeWarning: Columns (3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv('interrupcoes-energia-eletrica-2022.csv', encoding=\"ISO-8859-1\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv('interrupcoes-energia-eletrica-2022.csv', encoding=\"ISO-8859-1\", sep=';')\n",
    "df3=df3.dropna()\n",
    "df3=df3[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DatInicioInterrupcao','DatFimInterrupcao']]\n",
    "\n",
    "colunas_para_separar = ['DatInicioInterrupcao', 'DatFimInterrupcao']\n",
    "df3 = separar_data_hora(df3, colunas_para_separar)\n",
    "\n",
    "df3= processar_interrupcoes(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0098a19c-e865-4f07-9260-d7a9256d49d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1848\\2624106057.py:1: DtypeWarning: Columns (3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv('interrupcoes-energia-eletrica-2021.csv', encoding=\"ISO-8859-1\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('interrupcoes-energia-eletrica-2021.csv', encoding=\"ISO-8859-1\", sep=';')\n",
    "df4=df4.dropna()\n",
    "df4=df4[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DatInicioInterrupcao','DatFimInterrupcao']]\n",
    "\n",
    "colunas_para_separar = ['DatInicioInterrupcao', 'DatFimInterrupcao']\n",
    "df4 = separar_data_hora(df4, colunas_para_separar)\n",
    "\n",
    "df4= processar_interrupcoes(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1819ee15-c537-4202-ba76-bc379d918e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data= pd.concat([df1, df2,df3,df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75c4a57c-e190-4f6e-8dc4-0a46fe364406",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "cannot allocate memory for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6818\u001b[0m, in \u001b[0;36mDataFrame.drop_duplicates\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6815\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6816\u001b[0m ignore_index \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(ignore_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6818\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicated(subset, keep\u001b[38;5;241m=\u001b[39mkeep)]\n\u001b[0;32m   6819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[0;32m   6820\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6958\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6957\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[1;32m-> 6958\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(f, vals)))\n\u001b[0;32m   6960\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6926\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m-> 6926\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39mfactorize(vals, size_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   6927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[0;32m    796\u001b[0m         values,\n\u001b[0;32m    797\u001b[0m         use_na_sentinel\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    798\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[0;32m    799\u001b[0m     )\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[0;32m    596\u001b[0m     values,\n\u001b[0;32m    597\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    598\u001b[0m     na_value\u001b[38;5;241m=\u001b[39mna_value,\n\u001b[0;32m    599\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    600\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    601\u001b[0m )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2976\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2888\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable._unique\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:658\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64Vector.resize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: cannot allocate memory for array"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30700e-2483-45e6-bbb2-fb6151cc9053",
   "metadata": {},
   "source": [
    "### 1.4 Informa√ß√µes do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a45177-6f89-48a5-a501-a4340c6f96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o DataFrame est√° vazio\n",
    "if data.empty:\n",
    "    raise ValueError(\"Erro: O DataFrame est√° vazio ap√≥s o pr√©-processamento.\")\n",
    "\n",
    "# Verificar se h√° valores nulos\n",
    "print(\"Valores nulos por coluna:\\n\", data.isnull().sum())\n",
    "\n",
    "# Verificar n√∫mero de linhas e colunas\n",
    "print(f\"O DataFrame tem {data.shape[0]} linhas e {data.shape[1]} colunas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8a801-7375-4826-8271-5e0c384b8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que a coluna de datas seja 'DatInicioInterrupcao'\n",
    "menor_data = data['DatInicioInterrupcao'].min()\n",
    "maior_data = data['DatInicioInterrupcao'].max()\n",
    "\n",
    "print(f\"Menor data: {menor_data}\")\n",
    "print(f\"Maior data: {maior_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98548d-1739-409e-a870-5ec6752b672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c3c0c-7205-40b7-8244-6b0f99f6005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8746d8-7298-49f9-8de6-a50fb692ecda",
   "metadata": {},
   "source": [
    "### Continua√ß√£o do Pre-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a50f4-519d-41de-bc73-4f9ded7e2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que a coluna seja float\n",
    "data[\"NumNivelTensao\"] = pd.to_numeric(data[\"NumNivelTensao\"], errors='coerce')\n",
    "data[\"NumNivelTensao\"] = data[\"NumNivelTensao\"].apply(categorizar_numTensao)\n",
    "\n",
    "# Converter para categoria\n",
    "data[\"NumNivelTensao\"] = data[\"NumNivelTensao\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c78cc9-b78b-4b06-a6f4-896ebd2a99ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemplo de aplica√ß√£o no DataFrame:\n",
    "data['DuracaoInterrupcao'] = data['DuracaoInterrupcao'].apply(categorizar_duracao)\n",
    "# Converter para categoria\n",
    "data['DuracaoInterrupcao'] = data['DuracaoInterrupcao'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325dc09-df06-44f6-b1a1-2303946bd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Mes'] = data['DatInicioInterrupcao'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77de81-baf5-4d86-aed6-514524c7149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['FimInterrupcao'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42792a89-fda1-4943-8814-0177dc8fc13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que a coluna seja do tipo datetime (incluindo hora)\n",
    "data['InicioInterrupcao'] = pd.to_datetime(data['InicioInterrupcao'], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Agora, extrair apenas o hor√°rio corretamente\n",
    "data['HorInicioInterrupcao'] = data['InicioInterrupcao'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0209d9-b6c8-4e76-866d-28e42fcb22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd9a6c-e487-444b-afe3-a1921c07b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar a nova coluna 'Turno' aplicando a fun√ß√£o\n",
    "data['Turno'] = data['HorInicioInterrupcao'].apply(identificar_turno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6d04a-93b2-435d-bfd6-7e8001f4450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['DscTipoInterrupcao'] = data['DscTipoInterrupcao'].astype('category')\n",
    "data['SigAgente'] = data['SigAgente'].astype('category')\n",
    "data['DuracaoInterrupcao'] = data['DuracaoInterrupcao'].astype('category')\n",
    "data['IdeMotivoInterrupcao'] = data['IdeMotivoInterrupcao'].astype('category')\n",
    "data[\"Turno\"] = data[\"Turno\"].astype('category')\n",
    "data[\"Mes\"] = data[\"Mes\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782c65d-1411-4c16-be69-67e0c974aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afa41b-de26-4e45-8ab6-39254580567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DuracaoInterrupcao','Turno','Mes']]\n",
    "\n",
    "data.rename(columns={\n",
    "    'DscTipoInterrupcao': 'A',\n",
    "    'IdeMotivoInterrupcao': 'B',\n",
    "    'NumNivelTensao': 'C',\n",
    "    'SigAgente': 'D',\n",
    "    'DuracaoInterrupcao': 'E',\n",
    "    'Turno':'F',\n",
    "    'Mes': 'G'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb95f47-5e78-4ae3-bde5-9690111fc4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"D\"] = data[\"D\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec7afc-01e2-401e-9093-a2fee52ebe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o DataFrame est√° vazio\n",
    "if data.empty:\n",
    "    raise ValueError(\"Erro: O DataFrame est√° vazio ap√≥s o pr√©-processamento.\")\n",
    "\n",
    "# Verificar se h√° valores nulos\n",
    "print(\"Valores nulos por coluna:\\n\", data.isnull().sum())\n",
    "\n",
    "# Verificar n√∫mero de linhas e colunas\n",
    "print(f\"O DataFrame tem {data.shape[0]} linhas e {data.shape[1]} colunas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135867d-8906-4b88-b6fc-42a23dd7a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "# ‚úÖ 2. Aplicar Hill-Climbing Search para aprender a estrutura do modelo\n",
    "dag = HillClimbSearch(data).estimate(scoring_method=BicScore(data), max_indegree=3, max_iter=100)\n",
    "\n",
    "# ‚úÖ 3. Criar o modelo Bayesian com a estrutura aprendida\n",
    "best_model = BayesianModel(dag.edges())\n",
    "\n",
    "# ‚úÖ 4. Ajustar os par√¢metros do modelo usando os dados\n",
    "best_model.fit(data, estimator=BayesianEstimator, prior_type=\"BDeu\")\n",
    "\n",
    "# ‚úÖ 5. Exibir a estrutura aprendida\n",
    "print(\"Estrutura aprendida pelo Hill-Climbing Search:\", list(best_model.edges()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc08520-5bb0-40ce-a0c9-08aab2d4f3b6",
   "metadata": {},
   "source": [
    "# üîç Infer√™ncias Baseadas nas Rela√ß√µes da Rede Bayesiana\n",
    "\n",
    "## üìå Rela√ß√µes Estruturais\n",
    "Os pares **(X, Y)** indicam que **X influencia Y**, ou seja, **Y √© condicionado a X**.\n",
    "\n",
    "\n",
    "[('A', 'F'), ('B', 'D'), ('B', 'C'), ('B', 'G'), ('D', 'A'), ('D', 'G'), ('D', 'F'), ('C', 'D'), ('C', 'A'), ('C', 'G'), ('E', 'D'), ('E', 'F'), ('E', 'C'), ('E', 'B'), ('E', 'A')]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6193b-6698-42eb-abcd-03adcf1cb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = convert_to_networkx(best_model)\n",
    "image_path = plot_graph_and_save(graph, save_dir=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2efbf4-ddff-454c-951b-e38087057006",
   "metadata": {},
   "source": [
    "## **1Ô∏è‚É£ Infer√™ncia Simples**\n",
    "A infer√™ncia simples analisa as probabilidades das vari√°veis sem considerar nenhuma informa√ß√£o pr√©via.\n",
    "\n",
    "**Exemplo de Pergunta**  \n",
    "üìå *Qual a probabilidade de uma interrup√ß√£o ser programada ou acidental?*  \n",
    "üëâ `P(A)`\n",
    "\n",
    "**Exemplo de Resposta**\n",
    "- **Interrup√ß√£o programada**: 55%  \n",
    "- **Interrup√ß√£o acidental**: 45%  \n",
    "\n",
    "üìå *Qual a probabilidade do n√≠vel de tens√£o afetado ser baixa, m√©dia ou alta?*  \n",
    "üëâ `P(C)`\n",
    "\n",
    "- **Baixa tens√£o (127V-220V)**: 40%  \n",
    "- **M√©dia tens√£o (13.8kV)**: 35%  \n",
    "- **Alta tens√£o (69kV-138kV)**: 25%  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778299c-c541-4e09-b24f-467c7193b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_a = inferencia_simples(best_model, 'A')\n",
    "resultado_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31601d83-5168-46e4-aa14-b62bd5612413",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_b = inferencia_simples(best_model, 'B')\n",
    "resultado_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb28447-0e17-4ac5-89ae-75e3e0fbb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_c= inferencia_simples(best_model, 'C')\n",
    "resultado_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0ea69-499b-4fa5-9d5a-d6c917dff9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_d= inferencia_simples(best_model, 'D')\n",
    "resultado_d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551cb361-481d-4a81-b485-facbad9257c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_e= inferencia_simples(best_model, 'E')\n",
    "resultado_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61980f69-8548-46fd-9e56-ec85c940e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_f= inferencia_simples(best_model, 'F')\n",
    "resultado_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78643fcd-c1d2-4f41-8d49-a5d02bc3b09d",
   "metadata": {},
   "source": [
    "## **2Ô∏è‚É£ Infer√™ncia Condicional**\n",
    "Aqui analisamos probabilidades levando em conta informa√ß√µes conhecidas (**evid√™ncias**).\n",
    "\n",
    "### **üìå Infer√™ncias Baseadas nas Rela√ß√µes**\n",
    "Agora, usando as conex√µes na rede, podemos inferir:\n",
    "\n",
    "### üîπ **Probabilidade de um agente estar envolvido em uma falha, dado o motivo**\n",
    "**Pergunta**  \n",
    "üìå *Se a interrup√ß√£o ocorreu por sobrecarga (`B = sobrecarga`), qual a chance do agente respons√°vel ser a concession√°ria X?*  \n",
    "üëâ `P(D | B)`\n",
    "\n",
    "**Interpreta√ß√£o**\n",
    "- Se o motivo for **sobrecarga**, a interrup√ß√£o pode ter mais probabilidade de estar associada a distribuidoras locais.\n",
    "- Se for **falha estrutural**, pode estar mais associada a concession√°rias de transmiss√£o.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Probabilidade de o tipo de interrup√ß√£o ser programada ou acidental, dado o agente**\n",
    "**Pergunta**  \n",
    "üìå *Se a interrup√ß√£o ocorreu sob responsabilidade de uma determinada concession√°ria (`D = empresa X`), qual a probabilidade de ser uma falha programada?*  \n",
    "üëâ `P(A | D)`\n",
    "\n",
    "**Interpreta√ß√£o**\n",
    "- Empresas que realizam **muita manuten√ß√£o preventiva** t√™m mais interrup√ß√µes **programadas**.\n",
    "- Empresas com **infraestrutura deficiente** podem ter mais falhas **acidentais**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Impacto do n√≠vel de tens√£o no tipo de interrup√ß√£o**\n",
    "**Pergunta**  \n",
    "üìå *Se a falha ocorreu em uma rede de alta tens√£o (`C = alta tens√£o`), qual a chance de ser um desligamento programado?*  \n",
    "üëâ `P(A | C)`\n",
    "\n",
    "**Interpreta√ß√£o**\n",
    "- Redes **de alta tens√£o** s√£o mais propensas a **interrup√ß√µes programadas** (exemplo: manuten√ß√£o preventiva).\n",
    "- Redes **de baixa tens√£o** podem ter mais **falhas acidentais** (exemplo: curto-circuitos e sobrecargas).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Dura√ß√£o da interrup√ß√£o baseada no motivo e n√≠vel de tens√£o**\n",
    "**Pergunta**  \n",
    "üìå *Se a interrup√ß√£o foi causada por um curto-circuito (`B = curto-circuito`) em uma rede de baixa tens√£o (`C = baixa tens√£o`), qual o tempo m√©dio de restabelecimento?*  \n",
    "üëâ `P(E | B, C)`\n",
    "\n",
    "**Interpreta√ß√£o**\n",
    "- Curto-circuitos em **redes de baixa tens√£o** tendem a ser resolvidos mais rapidamente (`E < 2 horas`).\n",
    "- Falhas em **redes de alta tens√£o** exigem protocolos mais rigorosos e podem levar mais tempo (`E > 6 horas`).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Influ√™ncia do m√™s na dura√ß√£o das interrup√ß√µes**\n",
    "**Pergunta**  \n",
    "üìå *Se estamos no m√™s de janeiro (`G = janeiro`), qual a probabilidade da interrup√ß√£o durar mais de 6 horas?*  \n",
    "üëâ `P(E > 6h | G = janeiro)`\n",
    "\n",
    "**Interpreta√ß√£o**\n",
    "- Em meses chuvosos, as interrup√ß√µes podem ser mais longas devido a dificuldades no acesso das equipes.\n",
    "- No ver√£o, sobrecargas podem causar mais falhas, mas o tempo de resposta pode ser melhor planejado.\n",
    "\n",
    "---\n",
    "[('A', 'F'), ('B', 'D'), ('B', 'C'), ('B', 'G'), ('D', 'A'), ('D', 'G'), ('D', 'F'), ('C', 'D'), ('C', 'A'), ('C', 'G'), ('E', 'D'), ('E', 'F'), ('E', 'C'), ('E', 'B'), ('E', 'A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b903b4d-6ae5-4944-b400-1dd9618fac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = VariableElimination(best_model)\n",
    "resultado = infer.query(variables=[\"F\"], evidence={\"A\": 'Programada'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb2ccd-5eca-41d3-aba9-64b45b8c31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63566364-6798-427f-add6-c9ec70353440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar para testar todos os valores poss√≠veis de cada vari√°vel de evid√™ncia\n",
    "\n",
    "from pgmpy.inference import VariableElimination\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Criar o objeto de infer√™ncia\n",
    "infer = VariableElimination(best_model)\n",
    "\n",
    "# Definir os poss√≠veis estados das vari√°veis\n",
    "valores_variaveis = {\n",
    "    \"A\": ['Programada', 'N√£o Programada'],\n",
    "    \"B\": [0, 1, 2, 3, 4, 5, 6, 7,8],\n",
    "    \"C\": ['Baixa Tens√£o', 'M√©dia Tens√£o', 'Alta Tens√£o'],\n",
    "    \"D\": ['CEMIG-D', 'EQUATORIAL GO', 'COPEL-DIS', 'ENEL RJ', 'ENEL CE', 'Equatorial MA', \n",
    "          'ELETROPAULO', 'CPFL-PAULISTA', 'RGE SUL', 'Equatorial PA'],\n",
    "    \"E\": ['Anomalia', 'Grande em √°rea rural', 'Grande em √°rea urbana', 'Interrup√ß√£o muito pequena', \n",
    "          'Interrup√ß√£o pequena', 'M√©dia', 'Preocupante', 'Ru√≠do'],\n",
    "    \"F\": ['Manh√£', 'Tarde', 'Noite'],\n",
    "    \"G\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "}\n",
    "\n",
    "# Lista de rela√ß√µes entre vari√°veis (Evid√™ncia -> Vari√°vel Alvo)\n",
    "relacoes = [('A', 'F'), ('B', 'D'), ('B', 'C'), ('B', 'G'), ('D', 'A'), ('D', 'G'), ('D', 'F'),\n",
    "            ('C', 'D'), ('C', 'A'), ('C', 'G'), ('E', 'D'), ('E', 'F'), ('E', 'C'), ('E', 'B'), ('E', 'A')]\n",
    "\n",
    "# Lista para armazenar os resultados das infer√™ncias\n",
    "resultados_lista = []\n",
    "\n",
    "# Realizar a infer√™ncia para cada par de rela√ß√£o testando todos os valores poss√≠veis da evid√™ncia\n",
    "for evidencia, variavel in relacoes:\n",
    "    for valor_evidencia in valores_variaveis[evidencia]:  # Testando todos os valores poss√≠veis da evid√™ncia\n",
    "        try:\n",
    "            # Fazer infer√™ncia\n",
    "            resultado = infer.query(variables=[variavel], evidence={evidencia: valor_evidencia})\n",
    "\n",
    "            # Criar uma entrada para cada estado da vari√°vel inferida\n",
    "            for estado, probabilidade in zip(resultado.state_names[variavel], resultado.values):\n",
    "                resultados_lista.append({\n",
    "                    \"Vari√°vel Inferida\": variavel,\n",
    "                    \"Estado\": estado,\n",
    "                    \"Evid√™ncia\": f\"{evidencia} = {valor_evidencia}\",\n",
    "                    \"Probabilidade\": probabilidade\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao inferir para {evidencia} -> {variavel} com {valor_evidencia}: {e}\")\n",
    "\n",
    "# Criar DataFrame com os resultados\n",
    "df_resultados = pd.DataFrame(resultados_lista)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21920f8f-929c-46d0-94f2-a21b031c9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[\n",
    "    (df_resultados['Vari√°vel Inferida'] == 'D') & \n",
    "    (df_resultados['Evid√™ncia'].str.startswith(\"E =\")) & \n",
    "    (df_resultados['Estado'] == 'CEMIG-D')  # Filtrar apenas 'CEMIG-D'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a98ace-8717-4af1-aa53-d4f831b757d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[\n",
    "    (df_resultados['Vari√°vel Inferida'] == 'D') & \n",
    "    (df_resultados['Evid√™ncia'].str.startswith(\"B =\")) & \n",
    "    (df_resultados['Estado'] == 'CEMIG-D')  # Filtrar apenas 'CEMIG-D'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc573c-ae47-43fe-ae15-cef2fe4fb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[\n",
    "    (df_resultados['Vari√°vel Inferida'] == 'D') & \n",
    "    (df_resultados['Evid√™ncia'].str.startswith(\"F =\")) & \n",
    "    (df_resultados['Estado'] == 'CEMIG-D')  # Filtrar apenas 'CEMIG-D'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac25d2-2d7f-42cf-b188-270695187ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[\n",
    "    (df_resultados['Vari√°vel Inferida'] == 'D') & \n",
    "    (df_resultados['Evid√™ncia'].str.startswith(\"C =\")) & \n",
    "    (df_resultados['Estado'] == 'CEMIG-D')  # Filtrar apenas 'CEMIG-D'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199b28a-100d-4969-8ed6-f5c194ff39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'F') & (df_resultados['Evid√™ncia'].str.startswith(\"D = CEMIG-D\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16457fd3-912f-401e-9270-f89319792e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'A') & (df_resultados['Evid√™ncia'].str.startswith(\"D = CEMIG-D\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6563e90-f56d-4fb0-bf8d-add32837a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'A') & (df_resultados['Evid√™ncia'].str.startswith(\"D = CEMIG-D\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9bbe9-26f9-4779-8ff2-dc33cdd3ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'G') & (df_resultados['Evid√™ncia'].str.startswith(\"D = CEMIG-D\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fa18d-2070-4fbf-b566-09b1d442fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'F') & (df_resultados['Evid√™ncia'].str.startswith(\"A =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a9297-6773-445f-8f58-3b2944582348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'G') & (df_resultados['Evid√™ncia'].str.startswith(\"C =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027cdcf-8a34-4305-a72c-942a2a121c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'A') & (df_resultados['Evid√™ncia'].str.startswith(\"D =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013f637-de83-447a-82ae-192f72864dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'F') & (df_resultados['Evid√™ncia'].str.startswith(\"A =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46184ca6-0c6f-4ed4-b81b-7800f1552e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'F') & (df_resultados['Evid√™ncia'].str.startswith(\"A =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd83fe-f4cd-4c15-9d4e-cd7b09bcf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'C') & (df_resultados['Evid√™ncia'].str.startswith(\"B =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a93f1-63f4-462e-a0d6-9953285c1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'G') & (df_resultados['Evid√™ncia'].str.startswith(\"B = 1\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efeb57b-cba1-4d9c-a4b0-e8eeeb600aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'G') & (df_resultados['Evid√™ncia'].str.startswith(\"B = 6\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65e9d6-b4f8-4e09-972a-501ceceef206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Vari√°vel Inferida'] == 'A') & (df_resultados['Evid√™ncia'].str.startswith(\"E =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95433ad2-acd3-4a58-9d16-5a015e0d1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data[['A','B','C','E','G']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95ca32-cbb9-4071-9ee1-fd904963aa83",
   "metadata": {},
   "source": [
    "## 2.1 Gr√°ficos de Barras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222dd052-ba90-4afc-b48f-774fff0a90f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4823e-0480-442a-bc94-0d01d278dfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83da9f3-6da4-4168-a988-9f527a9ddc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad8ce3-95ab-45c3-a7c9-ef0bfe898803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d202161-668a-4ab0-ae72-3a56e0ba6f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03524dd-42b5-4741-946a-7f404d3d09c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85fa380-a218-44f6-a3f6-45c2c5ad2c6e",
   "metadata": {},
   "source": [
    "## 2.2 Gr√°ficos  Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00794ed0-aad0-4cb2-9658-98fe2d10aa34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884912bd-4a7d-4eaf-bf9d-27549b9e9e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab506f-eb26-4d23-93e1-a8c41250b9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f3a49-6eb6-4965-a3e0-4e752c9df0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a302daa-1cf9-41e0-87b4-ceaadea137e8",
   "metadata": {},
   "source": [
    "## 2.3 Gr√°ficos Fun√ß√£o de Distribui√ß√£o Acumulada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33395ba1-6202-4d6d-b52c-1470a76d10d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
