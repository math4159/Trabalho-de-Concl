{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c28c99-95d3-4435-a52f-727b5c569e9e",
   "metadata": {},
   "source": [
    "# *1.Trabalho de Conclusão de Curso*.\n",
    "\n",
    "    Esse Projeto tem como finalidade aplicar modelos bayesianos à uma base de dados Fornecida pela ANEEL, referente a interrupções elétricas. Busca-se analidar a relação probábilistica entre as variaveis de interrupção, horario, região, concessionária, tipo da interrupção, interrupção em certo nével de tensão e o fator de causalidade da interrupção. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94ba28-8c0b-49a4-b920-09feea1b32ce",
   "metadata": {},
   "source": [
    "### 1.2 Importação de Bibliotecas \n",
    "\n",
    "* Panadas: Aálises de Data Frames \n",
    "* Pgmpy: Aplicação de Redes Bayesianas \n",
    "* Numpy: Operações Matemáticas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037057f5-b6f4-45d1-bf83-58c2271b6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BayesianEstimator, HillClimbSearch, BicScore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a12a7-5f8c-4ffc-87ee-0a7c7fb39949",
   "metadata": {},
   "source": [
    "### 1.3 Funções Realizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcac511-84b2-4736-97af-d217e115fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_data_hora(data, colunas):\n",
    "    \"\"\"\n",
    "    Função para separar as colunas de data e hora em um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "    data (pd.DataFrame): DataFrame contendo as colunas a serem separadas.\n",
    "    colunas (list): Lista com os nomes das colunas a serem separadas.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame com as colunas de data e hora separadas.\n",
    "    \"\"\"\n",
    "    for coluna in colunas:\n",
    "        if coluna in data.columns:\n",
    "            data[[coluna, f'Hor{coluna[3:]}']] = data[coluna].str.split(' ', expand=True)\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ef48cd-25ad-4982-a031-dd6372a34674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_interrupcoes(data):\n",
    "    \"\"\"\n",
    "    Processa as colunas de data e hora em um DataFrame grande, combinando-as e calculando a duração da interrupção.\n",
    "    \n",
    "    Parâmetros:\n",
    "    data (pd.DataFrame): DataFrame contendo as colunas de data e hora.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame atualizado com colunas formatadas e a duração da interrupção.\n",
    "    \"\"\"\n",
    "\n",
    "    # Converter colunas de data para string (reduz memória se forem objetos)\n",
    "    data['DatInicioInterrupcao'] = data['DatInicioInterrupcao'].astype('string')\n",
    "    data['DatFimInterrupcao'] = data['DatFimInterrupcao'].astype('string')\n",
    "\n",
    "    # Concatenar data e hora para criar colunas completas de datetime\n",
    "    data['InicioInterrupcao'] = pd.to_datetime(\n",
    "        data['DatInicioInterrupcao'] + ' ' + data['HorInicioInterrupcao'], \n",
    "        errors='coerce',  # Evita erros se houver valores inválidos\n",
    "        format='%Y-%m-%d %H:%M:%S'  # Define o formato esperado para otimização\n",
    "    )\n",
    "\n",
    "    data['FimInterrupcao'] = pd.to_datetime(\n",
    "        data['DatFimInterrupcao'] + ' ' + data['HorFimInterrupcao'], \n",
    "        errors='coerce',\n",
    "        format='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "\n",
    "    # Converter datas para datetime com inferência de formato\n",
    "    data['DatInicioInterrupcao'] = pd.to_datetime(data['DatInicioInterrupcao'], errors='coerce')\n",
    "    data['DatFimInterrupcao'] = pd.to_datetime(data['DatFimInterrupcao'], errors='coerce')\n",
    "\n",
    "    # Calcular a duração da interrupção (em horas)\n",
    "    data['DuracaoInterrupcao'] = (data['FimInterrupcao'] - data['InicioInterrupcao']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Liberar memória removendo colunas desnecessárias\n",
    "    data.drop(columns=['HorInicioInterrupcao', 'HorFimInterrupcao'], inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c583393-a05f-4f8e-a081-a4b321a14da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_numTensao(numTensao):\n",
    "    if numTensao <= 1000.0:\n",
    "        return 'Baixa Tensão'\n",
    "    elif 1000.0 < numTensao <= 36000.0:\n",
    "        return 'Média Tensão'\n",
    "    elif numTensao > 36000.0:\n",
    "        return 'Alta Tensão'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6c04cb-9fee-4314-a520-7c985c042bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Função para classificar o turno\n",
    "def identificar_turno(horario):\n",
    "    # Extrair a hora do Timestamp\n",
    "    hora = horario.hour\n",
    "    if 6 <= hora < 12:\n",
    "        return 'Manhã'\n",
    "    elif 12 <= hora < 18:\n",
    "        return 'Tarde'\n",
    "    else:\n",
    "        return 'Noite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a72f128b-cec9-45c7-9e02-847115433531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_duracao(duracao):\n",
    "    \"\"\"\n",
    "    Categoriza a duração da interrupção em faixas predefinidas.\n",
    "\n",
    "    Parâmetros:\n",
    "    - duracao (float): Duração da interrupção em horas.\n",
    "\n",
    "    Retorna:\n",
    "    - str: Categoria correspondente à duração.\n",
    "    \"\"\"\n",
    "    if duracao < 0.05:\n",
    "        return 'Ruído'\n",
    "    elif 0.05 <= duracao < 0.25:\n",
    "        return 'Interrupção muito pequena'\n",
    "    elif 0.25 <= duracao < 0.5:\n",
    "        return 'Interrupção pequena'\n",
    "    elif 0.5 <= duracao < 3:\n",
    "        return 'Média'\n",
    "    elif 3 <= duracao < 6:\n",
    "        return 'Grande em área urbana'\n",
    "    elif 6 <= duracao < 10:\n",
    "        return 'Grande em área rural'\n",
    "    elif 10 <= duracao < 24:\n",
    "        return 'Preocupante'\n",
    "    else:  # duracao >= 24\n",
    "        return 'Anomalia'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957319f5-de40-4355-b331-32b8ec2585c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_networkx(bayesian_model):\n",
    "    \"\"\"\n",
    "    Converte um BayesianModel para um DiGraph do networkx.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(bayesian_model.nodes())\n",
    "    G.add_edges_from(bayesian_model.edges())\n",
    "    return G\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def plot_graph_and_save(model, save_dir=\"output\", filename=\"bayesian_network.png\"):\n",
    "    \"\"\"\n",
    "    Plota a estrutura da Rede Bayesiana e salva a imagem em um caminho definido.\n",
    "\n",
    "    Parâmetros:\n",
    "    - model (nx.DiGraph): Grafo direcionado representando o modelo Bayesiano.\n",
    "    - save_dir (str): Diretório onde a imagem será salva.\n",
    "    - filename (str): Nome do arquivo a ser salvo.\n",
    "\n",
    "    Retorna:\n",
    "    - Caminho do arquivo salvo.\n",
    "    \"\"\"\n",
    "\n",
    "    # Criar diretório se não existir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Definir caminho do arquivo\n",
    "    image_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    # Criar a figura e o layout do grafo\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(model)\n",
    "    nx.draw(model, pos, with_labels=True, node_color='lightblue', font_weight='bold', node_size=3000, edge_color=\"gray\")\n",
    "    plt.title(\"Estrutura da Rede Bayesiana\")\n",
    "\n",
    "    # Salvar imagem antes de exibir\n",
    "    plt.savefig(image_path, format=\"png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    return image_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80df51-4784-4fe7-b2ff-4231699b8f0d",
   "metadata": {},
   "source": [
    "## Função para inferencias e Estruturas Bayesianas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c7e51f-73d3-4488-adfa-f86d536ff55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "import pandas as pd\n",
    "\n",
    "def inferencia_simples(modelo, variavel):\n",
    "    \"\"\"\n",
    "    Realiza inferência para uma variável na Rede Bayesiana sem considerar evidências.\n",
    "\n",
    "    Parâmetros:\n",
    "    - modelo (BayesianModel): Modelo Bayesiano treinado.\n",
    "    - variavel (str): Variável de interesse para inferência.\n",
    "\n",
    "    Retorno:\n",
    "    - DataFrame contendo as probabilidades inferidas para a variável.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Criar o objeto de inferência\n",
    "        inferencia = VariableElimination(modelo)\n",
    "\n",
    "        # Realizar a inferência para a variável sem evidências\n",
    "        resultado = inferencia.query(variables=[variavel])\n",
    "\n",
    "        # Criar um DataFrame com os estados e suas probabilidades\n",
    "        df_resultados = pd.DataFrame({\n",
    "            'Variável': variavel,\n",
    "            'Estado': resultado.state_names[variavel],  # Estados possíveis da variável\n",
    "            'Probabilidade': resultado.values  # Probabilidades associadas a cada estado\n",
    "        })\n",
    "\n",
    "        return df_resultados\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao realizar inferência para '{variavel}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Exemplo de uso:\n",
    "# resultado = inferencia_simples(best_model, 'A')\n",
    "# print(resultado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ff019e-65c9-494e-bd61-23861672d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "def inferencia_todas_combinacoes(modelo, categorias):\n",
    "    \"\"\"\n",
    "    Realiza inferência Bayesiana para todas as variáveis do modelo, considerando\n",
    "    todas as possíveis combinações de evidências.\n",
    "\n",
    "    Parâmetros:\n",
    "    - modelo (BayesianModel): Modelo Bayesiano treinado.\n",
    "    - categorias (dict): Dicionário contendo as categorias de cada variável.\n",
    "\n",
    "    Retorno:\n",
    "    - DataFrame contendo todas as inferências realizadas.\n",
    "    \"\"\"\n",
    "    # Criar o objeto de inferência\n",
    "    inferencia = VariableElimination(modelo)\n",
    "    \n",
    "    # Lista para armazenar os resultados\n",
    "    resultados = []\n",
    "\n",
    "    # Percorrer todas as variáveis do modelo\n",
    "    for variavel_alvo in modelo.nodes():\n",
    "        # Criar combinações de evidências usando as demais variáveis\n",
    "        variaveis_restantes = [var for var in modelo.nodes() if var != variavel_alvo]\n",
    "        \n",
    "        # Gerar todas as combinações possíveis de evidências\n",
    "        for num_evidencias in range(1, len(variaveis_restantes) + 1):  # De 1 até todas as evidências possíveis\n",
    "            for evidencias_comb in itertools.combinations(variaveis_restantes, num_evidencias):\n",
    "                # Gerar todas as combinações de valores para as evidências escolhidas\n",
    "                valores_possiveis = [categorias[var] for var in evidencias_comb]\n",
    "                for valores_evidencias in itertools.product(*valores_possiveis):\n",
    "                    # Criar o dicionário de evidências\n",
    "                    evidencias = dict(zip(evidencias_comb, valores_evidencias))\n",
    "\n",
    "                    # Mapear evidências categóricas para valores numéricos\n",
    "                    evidencias_convertidas = {}\n",
    "                    for var, valor in evidencias.items():\n",
    "                        cpd = modelo.get_cpds(var)\n",
    "                        categorias_var = cpd.state_names[var]\n",
    "                        evidencias_convertidas[var] = categorias_var.index(valor)\n",
    "\n",
    "                    # Realizar inferência\n",
    "                    resultado = inferencia.query(variables=[variavel_alvo], evidence=evidencias_convertidas)\n",
    "\n",
    "                    # Adicionar os resultados ao DataFrame\n",
    "                    for estado, prob in zip(resultado.state_names[variavel_alvo], resultado.values):\n",
    "                        resultados.append({\n",
    "                            'Variável Alvo': variavel_alvo,\n",
    "                            'Estado': estado,\n",
    "                            'Probabilidade': prob,\n",
    "                            'Evidências': evidencias\n",
    "                        })\n",
    "\n",
    "    # Criar um DataFrame com os resultados\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "    return df_resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ffa12-7836-4dea-bc50-95ba26094b73",
   "metadata": {},
   "source": [
    "### 1.3 Exportação da Base de Dados e Pré-processamento\n",
    "    O Pgmpy não aceita objetct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28531555-278b-4044-b6bd-0a4c4c95d27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1848\\2716428666.py:1: DtypeWarning: Columns (0,2,3,4,5,6,8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv('interrupcoes-energia-eletrica-2024 (2).csv', encoding=\"ISO-8859-1\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('interrupcoes-energia-eletrica-2024 (2).csv', encoding=\"ISO-8859-1\", sep=';')\n",
    "df1=df1.dropna()\n",
    "df1=df1[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DatInicioInterrupcao','DatFimInterrupcao']]\n",
    "\n",
    "colunas_para_separar = ['DatInicioInterrupcao', 'DatFimInterrupcao']\n",
    "df1 = separar_data_hora(df1, colunas_para_separar)\n",
    "\n",
    "df1= processar_interrupcoes(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "945dd977-490a-4834-88e1-9741d514b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1848\\2955413010.py:1: DtypeWarning: Columns (3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('interrupcoes-energia-eletrica-2023.csv', encoding=\"ISO-8859-1\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('interrupcoes-energia-eletrica-2023.csv', encoding=\"ISO-8859-1\", sep=';')\n",
    "df2=df2.dropna()\n",
    "df2=df2[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DatInicioInterrupcao','DatFimInterrupcao']]\n",
    "\n",
    "colunas_para_separar = ['DatInicioInterrupcao', 'DatFimInterrupcao']\n",
    "df2 = separar_data_hora(df2, colunas_para_separar)\n",
    "\n",
    "df2= processar_interrupcoes(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "486b1cd4-4c05-4378-bca5-f14942047277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1848\\1339177106.py:1: DtypeWarning: Columns (3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv('interrupcoes-energia-eletrica-2022.csv', encoding=\"ISO-8859-1\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv('interrupcoes-energia-eletrica-2022.csv', encoding=\"ISO-8859-1\", sep=';')\n",
    "df3=df3.dropna()\n",
    "df3=df3[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DatInicioInterrupcao','DatFimInterrupcao']]\n",
    "\n",
    "colunas_para_separar = ['DatInicioInterrupcao', 'DatFimInterrupcao']\n",
    "df3 = separar_data_hora(df3, colunas_para_separar)\n",
    "\n",
    "df3= processar_interrupcoes(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0098a19c-e865-4f07-9260-d7a9256d49d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1848\\2624106057.py:1: DtypeWarning: Columns (3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv('interrupcoes-energia-eletrica-2021.csv', encoding=\"ISO-8859-1\", sep=';')\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('interrupcoes-energia-eletrica-2021.csv', encoding=\"ISO-8859-1\", sep=';')\n",
    "df4=df4.dropna()\n",
    "df4=df4[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DatInicioInterrupcao','DatFimInterrupcao']]\n",
    "\n",
    "colunas_para_separar = ['DatInicioInterrupcao', 'DatFimInterrupcao']\n",
    "df4 = separar_data_hora(df4, colunas_para_separar)\n",
    "\n",
    "df4= processar_interrupcoes(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1819ee15-c537-4202-ba76-bc379d918e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data= pd.concat([df1, df2,df3,df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75c4a57c-e190-4f6e-8dc4-0a46fe364406",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "cannot allocate memory for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6818\u001b[0m, in \u001b[0;36mDataFrame.drop_duplicates\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6815\u001b[0m inplace \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(inplace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6816\u001b[0m ignore_index \u001b[38;5;241m=\u001b[39m validate_bool_kwarg(ignore_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 6818\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicated(subset, keep\u001b[38;5;241m=\u001b[39mkeep)]\n\u001b[0;32m   6819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[0;32m   6820\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6958\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6957\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[1;32m-> 6958\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(f, vals)))\n\u001b[0;32m   6960\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:6926\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m-> 6926\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39mfactorize(vals, size_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   6927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[0;32m    796\u001b[0m         values,\n\u001b[0;32m    797\u001b[0m         use_na_sentinel\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    798\u001b[0m         size_hint\u001b[38;5;241m=\u001b[39msize_hint,\n\u001b[0;32m    799\u001b[0m     )\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[0;32m    596\u001b[0m     values,\n\u001b[0;32m    597\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    598\u001b[0m     na_value\u001b[38;5;241m=\u001b[39mna_value,\n\u001b[0;32m    599\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    600\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    601\u001b[0m )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2976\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2888\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable._unique\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:658\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64Vector.resize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: cannot allocate memory for array"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30700e-2483-45e6-bbb2-fb6151cc9053",
   "metadata": {},
   "source": [
    "### 1.4 Informações do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a45177-6f89-48a5-a501-a4340c6f96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o DataFrame está vazio\n",
    "if data.empty:\n",
    "    raise ValueError(\"Erro: O DataFrame está vazio após o pré-processamento.\")\n",
    "\n",
    "# Verificar se há valores nulos\n",
    "print(\"Valores nulos por coluna:\\n\", data.isnull().sum())\n",
    "\n",
    "# Verificar número de linhas e colunas\n",
    "print(f\"O DataFrame tem {data.shape[0]} linhas e {data.shape[1]} colunas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8a801-7375-4826-8271-5e0c384b8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que a coluna de datas seja 'DatInicioInterrupcao'\n",
    "menor_data = data['DatInicioInterrupcao'].min()\n",
    "maior_data = data['DatInicioInterrupcao'].max()\n",
    "\n",
    "print(f\"Menor data: {menor_data}\")\n",
    "print(f\"Maior data: {maior_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98548d-1739-409e-a870-5ec6752b672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c3c0c-7205-40b7-8244-6b0f99f6005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8746d8-7298-49f9-8de6-a50fb692ecda",
   "metadata": {},
   "source": [
    "### Continuação do Pre-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a50f4-519d-41de-bc73-4f9ded7e2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que a coluna seja float\n",
    "data[\"NumNivelTensao\"] = pd.to_numeric(data[\"NumNivelTensao\"], errors='coerce')\n",
    "data[\"NumNivelTensao\"] = data[\"NumNivelTensao\"].apply(categorizar_numTensao)\n",
    "\n",
    "# Converter para categoria\n",
    "data[\"NumNivelTensao\"] = data[\"NumNivelTensao\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c78cc9-b78b-4b06-a6f4-896ebd2a99ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemplo de aplicação no DataFrame:\n",
    "data['DuracaoInterrupcao'] = data['DuracaoInterrupcao'].apply(categorizar_duracao)\n",
    "# Converter para categoria\n",
    "data['DuracaoInterrupcao'] = data['DuracaoInterrupcao'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325dc09-df06-44f6-b1a1-2303946bd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Mes'] = data['DatInicioInterrupcao'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77de81-baf5-4d86-aed6-514524c7149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['FimInterrupcao'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42792a89-fda1-4943-8814-0177dc8fc13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que a coluna seja do tipo datetime (incluindo hora)\n",
    "data['InicioInterrupcao'] = pd.to_datetime(data['InicioInterrupcao'], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Agora, extrair apenas o horário corretamente\n",
    "data['HorInicioInterrupcao'] = data['InicioInterrupcao'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0209d9-b6c8-4e76-866d-28e42fcb22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd9a6c-e487-444b-afe3-a1921c07b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar a nova coluna 'Turno' aplicando a função\n",
    "data['Turno'] = data['HorInicioInterrupcao'].apply(identificar_turno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6d04a-93b2-435d-bfd6-7e8001f4450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['DscTipoInterrupcao'] = data['DscTipoInterrupcao'].astype('category')\n",
    "data['SigAgente'] = data['SigAgente'].astype('category')\n",
    "data['DuracaoInterrupcao'] = data['DuracaoInterrupcao'].astype('category')\n",
    "data['IdeMotivoInterrupcao'] = data['IdeMotivoInterrupcao'].astype('category')\n",
    "data[\"Turno\"] = data[\"Turno\"].astype('category')\n",
    "data[\"Mes\"] = data[\"Mes\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782c65d-1411-4c16-be69-67e0c974aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afa41b-de26-4e45-8ab6-39254580567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['DscTipoInterrupcao','IdeMotivoInterrupcao','NumNivelTensao','SigAgente','DuracaoInterrupcao','Turno','Mes']]\n",
    "\n",
    "data.rename(columns={\n",
    "    'DscTipoInterrupcao': 'A',\n",
    "    'IdeMotivoInterrupcao': 'B',\n",
    "    'NumNivelTensao': 'C',\n",
    "    'SigAgente': 'D',\n",
    "    'DuracaoInterrupcao': 'E',\n",
    "    'Turno':'F',\n",
    "    'Mes': 'G'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb95f47-5e78-4ae3-bde5-9690111fc4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"D\"] = data[\"D\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec7afc-01e2-401e-9093-a2fee52ebe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o DataFrame está vazio\n",
    "if data.empty:\n",
    "    raise ValueError(\"Erro: O DataFrame está vazio após o pré-processamento.\")\n",
    "\n",
    "# Verificar se há valores nulos\n",
    "print(\"Valores nulos por coluna:\\n\", data.isnull().sum())\n",
    "\n",
    "# Verificar número de linhas e colunas\n",
    "print(f\"O DataFrame tem {data.shape[0]} linhas e {data.shape[1]} colunas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135867d-8906-4b88-b6fc-42a23dd7a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "# ✅ 2. Aplicar Hill-Climbing Search para aprender a estrutura do modelo\n",
    "dag = HillClimbSearch(data).estimate(scoring_method=BicScore(data), max_indegree=3, max_iter=100)\n",
    "\n",
    "# ✅ 3. Criar o modelo Bayesian com a estrutura aprendida\n",
    "best_model = BayesianModel(dag.edges())\n",
    "\n",
    "# ✅ 4. Ajustar os parâmetros do modelo usando os dados\n",
    "best_model.fit(data, estimator=BayesianEstimator, prior_type=\"BDeu\")\n",
    "\n",
    "# ✅ 5. Exibir a estrutura aprendida\n",
    "print(\"Estrutura aprendida pelo Hill-Climbing Search:\", list(best_model.edges()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc08520-5bb0-40ce-a0c9-08aab2d4f3b6",
   "metadata": {},
   "source": [
    "# 🔍 Inferências Baseadas nas Relações da Rede Bayesiana\n",
    "\n",
    "## 📌 Relações Estruturais\n",
    "Os pares **(X, Y)** indicam que **X influencia Y**, ou seja, **Y é condicionado a X**.\n",
    "\n",
    "\n",
    "[('A', 'F'), ('B', 'D'), ('B', 'C'), ('B', 'G'), ('D', 'A'), ('D', 'G'), ('D', 'F'), ('C', 'D'), ('C', 'A'), ('C', 'G'), ('E', 'D'), ('E', 'F'), ('E', 'C'), ('E', 'B'), ('E', 'A')]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6193b-6698-42eb-abcd-03adcf1cb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = convert_to_networkx(best_model)\n",
    "image_path = plot_graph_and_save(graph, save_dir=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2efbf4-ddff-454c-951b-e38087057006",
   "metadata": {},
   "source": [
    "## **1️⃣ Inferência Simples**\n",
    "A inferência simples analisa as probabilidades das variáveis sem considerar nenhuma informação prévia.\n",
    "\n",
    "**Exemplo de Pergunta**  \n",
    "📌 *Qual a probabilidade de uma interrupção ser programada ou acidental?*  \n",
    "👉 `P(A)`\n",
    "\n",
    "**Exemplo de Resposta**\n",
    "- **Interrupção programada**: 55%  \n",
    "- **Interrupção acidental**: 45%  \n",
    "\n",
    "📌 *Qual a probabilidade do nível de tensão afetado ser baixa, média ou alta?*  \n",
    "👉 `P(C)`\n",
    "\n",
    "- **Baixa tensão (127V-220V)**: 40%  \n",
    "- **Média tensão (13.8kV)**: 35%  \n",
    "- **Alta tensão (69kV-138kV)**: 25%  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778299c-c541-4e09-b24f-467c7193b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_a = inferencia_simples(best_model, 'A')\n",
    "resultado_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31601d83-5168-46e4-aa14-b62bd5612413",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_b = inferencia_simples(best_model, 'B')\n",
    "resultado_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb28447-0e17-4ac5-89ae-75e3e0fbb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_c= inferencia_simples(best_model, 'C')\n",
    "resultado_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0ea69-499b-4fa5-9d5a-d6c917dff9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_d= inferencia_simples(best_model, 'D')\n",
    "resultado_d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551cb361-481d-4a81-b485-facbad9257c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_e= inferencia_simples(best_model, 'E')\n",
    "resultado_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61980f69-8548-46fd-9e56-ec85c940e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_f= inferencia_simples(best_model, 'F')\n",
    "resultado_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78643fcd-c1d2-4f41-8d49-a5d02bc3b09d",
   "metadata": {},
   "source": [
    "## **2️⃣ Inferência Condicional**\n",
    "Aqui analisamos probabilidades levando em conta informações conhecidas (**evidências**).\n",
    "\n",
    "### **📌 Inferências Baseadas nas Relações**\n",
    "Agora, usando as conexões na rede, podemos inferir:\n",
    "\n",
    "### 🔹 **Probabilidade de um agente estar envolvido em uma falha, dado o motivo**\n",
    "**Pergunta**  \n",
    "📌 *Se a interrupção ocorreu por sobrecarga (`B = sobrecarga`), qual a chance do agente responsável ser a concessionária X?*  \n",
    "👉 `P(D | B)`\n",
    "\n",
    "**Interpretação**\n",
    "- Se o motivo for **sobrecarga**, a interrupção pode ter mais probabilidade de estar associada a distribuidoras locais.\n",
    "- Se for **falha estrutural**, pode estar mais associada a concessionárias de transmissão.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Probabilidade de o tipo de interrupção ser programada ou acidental, dado o agente**\n",
    "**Pergunta**  \n",
    "📌 *Se a interrupção ocorreu sob responsabilidade de uma determinada concessionária (`D = empresa X`), qual a probabilidade de ser uma falha programada?*  \n",
    "👉 `P(A | D)`\n",
    "\n",
    "**Interpretação**\n",
    "- Empresas que realizam **muita manutenção preventiva** têm mais interrupções **programadas**.\n",
    "- Empresas com **infraestrutura deficiente** podem ter mais falhas **acidentais**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Impacto do nível de tensão no tipo de interrupção**\n",
    "**Pergunta**  \n",
    "📌 *Se a falha ocorreu em uma rede de alta tensão (`C = alta tensão`), qual a chance de ser um desligamento programado?*  \n",
    "👉 `P(A | C)`\n",
    "\n",
    "**Interpretação**\n",
    "- Redes **de alta tensão** são mais propensas a **interrupções programadas** (exemplo: manutenção preventiva).\n",
    "- Redes **de baixa tensão** podem ter mais **falhas acidentais** (exemplo: curto-circuitos e sobrecargas).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Duração da interrupção baseada no motivo e nível de tensão**\n",
    "**Pergunta**  \n",
    "📌 *Se a interrupção foi causada por um curto-circuito (`B = curto-circuito`) em uma rede de baixa tensão (`C = baixa tensão`), qual o tempo médio de restabelecimento?*  \n",
    "👉 `P(E | B, C)`\n",
    "\n",
    "**Interpretação**\n",
    "- Curto-circuitos em **redes de baixa tensão** tendem a ser resolvidos mais rapidamente (`E < 2 horas`).\n",
    "- Falhas em **redes de alta tensão** exigem protocolos mais rigorosos e podem levar mais tempo (`E > 6 horas`).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Influência do mês na duração das interrupções**\n",
    "**Pergunta**  \n",
    "📌 *Se estamos no mês de janeiro (`G = janeiro`), qual a probabilidade da interrupção durar mais de 6 horas?*  \n",
    "👉 `P(E > 6h | G = janeiro)`\n",
    "\n",
    "**Interpretação**\n",
    "- Em meses chuvosos, as interrupções podem ser mais longas devido a dificuldades no acesso das equipes.\n",
    "- No verão, sobrecargas podem causar mais falhas, mas o tempo de resposta pode ser melhor planejado.\n",
    "\n",
    "---\n",
    "[('A', 'F'), ('B', 'D'), ('B', 'C'), ('B', 'G'), ('D', 'A'), ('D', 'G'), ('D', 'F'), ('C', 'D'), ('C', 'A'), ('C', 'G'), ('E', 'D'), ('E', 'F'), ('E', 'C'), ('E', 'B'), ('E', 'A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b903b4d-6ae5-4944-b400-1dd9618fac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = VariableElimination(best_model)\n",
    "resultado = infer.query(variables=[\"F\"], evidence={\"A\": 'Programada'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb2ccd-5eca-41d3-aba9-64b45b8c31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63566364-6798-427f-add6-c9ec70353440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar para testar todos os valores possíveis de cada variável de evidência\n",
    "\n",
    "from pgmpy.inference import VariableElimination\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Criar o objeto de inferência\n",
    "infer = VariableElimination(best_model)\n",
    "\n",
    "# Definir os possíveis estados das variáveis\n",
    "valores_variaveis = {\n",
    "    \"A\": ['Programada', 'Não Programada'],\n",
    "    \"B\": [0, 1, 2, 3, 4, 5, 6, 7,8],\n",
    "    \"C\": ['Baixa Tensão', 'Média Tensão', 'Alta Tensão'],\n",
    "    \"D\": ['CEMIG-D', 'EQUATORIAL GO', 'COPEL-DIS', 'ENEL RJ', 'ENEL CE', 'Equatorial MA', \n",
    "          'ELETROPAULO', 'CPFL-PAULISTA', 'RGE SUL', 'Equatorial PA'],\n",
    "    \"E\": ['Anomalia', 'Grande em área rural', 'Grande em área urbana', 'Interrupção muito pequena', \n",
    "          'Interrupção pequena', 'Média', 'Preocupante', 'Ruído'],\n",
    "    \"F\": ['Manhã', 'Tarde', 'Noite'],\n",
    "    \"G\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "}\n",
    "\n",
    "# Lista de relações entre variáveis (Evidência -> Variável Alvo)\n",
    "relacoes = [('A', 'F'), ('B', 'D'), ('B', 'C'), ('B', 'G'), ('D', 'A'), ('D', 'G'), ('D', 'F'),\n",
    "            ('C', 'D'), ('C', 'A'), ('C', 'G'), ('E', 'D'), ('E', 'F'), ('E', 'C'), ('E', 'B'), ('E', 'A')]\n",
    "\n",
    "# Lista para armazenar os resultados das inferências\n",
    "resultados_lista = []\n",
    "\n",
    "# Realizar a inferência para cada par de relação testando todos os valores possíveis da evidência\n",
    "for evidencia, variavel in relacoes:\n",
    "    for valor_evidencia in valores_variaveis[evidencia]:  # Testando todos os valores possíveis da evidência\n",
    "        try:\n",
    "            # Fazer inferência\n",
    "            resultado = infer.query(variables=[variavel], evidence={evidencia: valor_evidencia})\n",
    "\n",
    "            # Criar uma entrada para cada estado da variável inferida\n",
    "            for estado, probabilidade in zip(resultado.state_names[variavel], resultado.values):\n",
    "                resultados_lista.append({\n",
    "                    \"Variável Inferida\": variavel,\n",
    "                    \"Estado\": estado,\n",
    "                    \"Evidência\": f\"{evidencia} = {valor_evidencia}\",\n",
    "                    \"Probabilidade\": probabilidade\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao inferir para {evidencia} -> {variavel} com {valor_evidencia}: {e}\")\n",
    "\n",
    "# Criar DataFrame com os resultados\n",
    "df_resultados = pd.DataFrame(resultados_lista)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21920f8f-929c-46d0-94f2-a21b031c9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[\n",
    "    (df_resultados['Variável Inferida'] == 'D') & \n",
    "    (df_resultados['Evidência'].str.startswith(\"E =\")) & \n",
    "    (df_resultados['Estado'] == 'CEMIG-D')  # Filtrar apenas 'CEMIG-D'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a98ace-8717-4af1-aa53-d4f831b757d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[\n",
    "    (df_resultados['Variável Inferida'] == 'D') & \n",
    "    (df_resultados['Evidência'].str.startswith(\"B =\")) & \n",
    "    (df_resultados['Estado'] == 'CEMIG-D')  # Filtrar apenas 'CEMIG-D'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc573c-ae47-43fe-ae15-cef2fe4fb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[\n",
    "    (df_resultados['Variável Inferida'] == 'D') & \n",
    "    (df_resultados['Evidência'].str.startswith(\"F =\")) & \n",
    "    (df_resultados['Estado'] == 'CEMIG-D')  # Filtrar apenas 'CEMIG-D'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac25d2-2d7f-42cf-b188-270695187ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[\n",
    "    (df_resultados['Variável Inferida'] == 'D') & \n",
    "    (df_resultados['Evidência'].str.startswith(\"C =\")) & \n",
    "    (df_resultados['Estado'] == 'CEMIG-D')  # Filtrar apenas 'CEMIG-D'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199b28a-100d-4969-8ed6-f5c194ff39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'F') & (df_resultados['Evidência'].str.startswith(\"D = CEMIG-D\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16457fd3-912f-401e-9270-f89319792e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'A') & (df_resultados['Evidência'].str.startswith(\"D = CEMIG-D\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6563e90-f56d-4fb0-bf8d-add32837a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'A') & (df_resultados['Evidência'].str.startswith(\"D = CEMIG-D\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9bbe9-26f9-4779-8ff2-dc33cdd3ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'G') & (df_resultados['Evidência'].str.startswith(\"D = CEMIG-D\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fa18d-2070-4fbf-b566-09b1d442fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'F') & (df_resultados['Evidência'].str.startswith(\"A =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a9297-6773-445f-8f58-3b2944582348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'G') & (df_resultados['Evidência'].str.startswith(\"C =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027cdcf-8a34-4305-a72c-942a2a121c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'A') & (df_resultados['Evidência'].str.startswith(\"D =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013f637-de83-447a-82ae-192f72864dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'F') & (df_resultados['Evidência'].str.startswith(\"A =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46184ca6-0c6f-4ed4-b81b-7800f1552e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'F') & (df_resultados['Evidência'].str.startswith(\"A =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd83fe-f4cd-4c15-9d4e-cd7b09bcf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'C') & (df_resultados['Evidência'].str.startswith(\"B =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a93f1-63f4-462e-a0d6-9953285c1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'G') & (df_resultados['Evidência'].str.startswith(\"B = 1\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efeb57b-cba1-4d9c-a4b0-e8eeeb600aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'G') & (df_resultados['Evidência'].str.startswith(\"B = 6\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65e9d6-b4f8-4e09-972a-501ceceef206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados[(df_resultados['Variável Inferida'] == 'A') & (df_resultados['Evidência'].str.startswith(\"E =\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95433ad2-acd3-4a58-9d16-5a015e0d1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data[['A','B','C','E','G']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95ca32-cbb9-4071-9ee1-fd904963aa83",
   "metadata": {},
   "source": [
    "## 2.1 Gráficos de Barras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222dd052-ba90-4afc-b48f-774fff0a90f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4823e-0480-442a-bc94-0d01d278dfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83da9f3-6da4-4168-a988-9f527a9ddc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad8ce3-95ab-45c3-a7c9-ef0bfe898803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d202161-668a-4ab0-ae72-3a56e0ba6f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03524dd-42b5-4741-946a-7f404d3d09c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85fa380-a218-44f6-a3f6-45c2c5ad2c6e",
   "metadata": {},
   "source": [
    "## 2.2 Gráficos  Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00794ed0-aad0-4cb2-9658-98fe2d10aa34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884912bd-4a7d-4eaf-bf9d-27549b9e9e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab506f-eb26-4d23-93e1-a8c41250b9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f3a49-6eb6-4965-a3e0-4e752c9df0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a302daa-1cf9-41e0-87b4-ceaadea137e8",
   "metadata": {},
   "source": [
    "## 2.3 Gráficos Função de Distribuição Acumulada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33395ba1-6202-4d6d-b52c-1470a76d10d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
